1. 百度IDL：无给定条件，预测蔬菜价格。 提几个特征做预测模型：
   + 肉的价格、土壤健康指标、天气情况、国民收入、货币汇率等等。
   
2. 根据目标表的数据判断其来自于上游十个表的哪
   + （我从数据分布，概率统计角度回答的）应该要用到数据血缘之类的。
   
3. 关键词抽取

   + 可以认为是「文本标签提取」，这个标签在一定程度上能够表现出这个句子的含义

   + 这些标签有时候可以用在推荐系统的召回

   + 抽取式和生成式

     + 生成式的结果不可控
     + 抽取式就是从现有的数据中拿出来词组，最差的结果也就是取出的词不是我们想要的（主要关注）

   + 召回：

     + 得到文本中的候选关键词，也就是有可能是关键词的词，具体方法：
       + 根据积累的关键词库，直接匹配出来
       + 一些符合词性的候选词，比如名词
       + 基于统计特征提出候选词，比如TF-IDF
       + 根据一些规则，一个句子中同时出现人名，地名，机构名时，这些带名的词
     + 原则：尽可能多的召回有用的词，宁多勿少

   + 排序

     + 无监督

       + 基于统计，baseline为TF-IDF，需要去掉常用停用词，缺点是没有考虑词之间，词与文档间的关系，是割裂的
       + 基于图，baseline为 TextRank，其考虑了词与词之间的关系，但是其针对单个文本，不是对真整个语料

     + 有监督，二分类

       + 找到词汇的各种特征，去判断这个词汇是不是这个文本的关键词，比如：

       1. 位置特征：是否出现在开头，是否出现在中间部分，是否出现在末尾，出现的位置（具体是第几个单词）；相对于整个文本的位置；是否出现在# #符号之间...

       2. 统计特征：共现矩阵信息；词频；逆词频；词性；词跨度；关键词所在句子的最大长度/最小长度/平均长度;

       3. 向量特征：关键词词向量和文档向量的相似性

     + 有监督，序列标注

       + HMM
       + CRF

   + 新词的发现

     + 从文本的自由程度和凝固程度来判断是否是新词，问题是阈值不好调整从而导致召回和精准不好平衡
     + 离线挖掘实体词补充到词库中
       1. 挖掘频繁项
       2. 提取频繁项的各种统计特征
       3. 频繁项和已经有的实体交集作为正样本，负采样得到负样本。使用多个分类器进行集成，训练多个二元分类器。（问题：正样本数据是相对搭配的，并且文本较短）
       4. 搜索日志中搜索次数比较高的词条和正样本的交集作为高质量短语，负样本减去词条作为低质量短语，使用Bert训练质量打分器。（打分器的可靠性，实体库如何分类）



基于预训练的自然语言生成在搜索和广告中的应用

阿里PLUG

百度知识增强技术ERNIE

多模态



#### UGC内容挖掘

+ UGC：user generated content，用户为互联网内容的产生者和供应者
+ 基于UGC的数据，可以挖掘出用户情感分布、用户偏好、以及优质语料等有价值的信息。基于这些数据挖掘，可以提升用户体验，与百度内容生态结合，构建出更具想象力的商业形态。
+ 技术难点：
  + UGC主题比较分散
    + 将多主题的UGC切割为多个单主题子UGC；
    + 真正想要的是一条UGC对应一个推荐菜，并且在UGC中尽量不提及其他推荐菜
  + 预测UGC所表达的感情色彩
    + 运用情感分析手段预测用户表达的感情色彩
    + 情感色彩可以是正向、中性、负向，也可以是具体的人类的情感
    + 提取正向UGC作为推荐菜的描述
  + 关键词稀疏，相似度计算困难。
    + 在词面相似度的基础上，应用word2vec模型从语义方向计算关键词之间的相似度。
    + 根据推荐得到的核心词特征比较稀疏，根据稀疏特征召回推荐菜准确率非常低，而且计算量大。
    + 我们的做法是将所有UGC作为训练语料，训练word2vec模型，利用word2vec计算核心词和推荐菜的相似度，从而为子UGC召回推荐菜。
    + 排序范围是某一个门店下某一个推荐菜的所有UGC，主要从情感得分、推荐菜与UGC的关联度（核心词与推荐菜的相似度）、UGC长度特征（可以按照正态分布函数计算得分）进行综合排序。
  + PM抽样评估



+ spam内容识别
  + 