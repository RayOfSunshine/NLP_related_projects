### 究竟为什么要用BiLSTM+CRF模型来解决实体识别任务？

https://zhuanlan.zhihu.com/p/44042528

==针对一个项目的常见问法==：

1. 为什么要选择这个模型？
2. 特征工程是如何做到？
3. 现在使用的方法有什么缺点，如何进行改进？
4. CRF为什么能做到全局考虑，什么原理和模型？
   1. CRF中会考虑两类分数，分别是状态分数和转移分数。状态分数由BiLSTM结果得出，表示某个位置的字被预测为某一个标签的概率；状态分数表示一个预测为标签A后，下一个被预测为标签B的概率，不合理的实体类型转移的分数就会非常低，在CRF的计算中就会抛弃这些分数很低的转移情况。其使用的目标函数是真实路径上的分数除以所有路径上的分数和，每条路径的分数就是通过状态分数和转移分数计算出来的

#### BiLSTM+CRF模型

训练句子中每个词是一条包含词嵌入和字嵌入的词向量，词嵌入通常是事先训练好的，字嵌入则是随机初始化的。BiLSTM-CRF的输入是词嵌入向量，输出是每个单词对应的预测标签。

![截屏2021-05-21 上午11.17.14](/Users/lixuanhong/Library/Application Support/typora-user-images/截屏2021-05-21 上午11.17.14.png)

==自评==：对于英文来说，这里的字其实就是单词；而对于中文来说，这里的字是一个汉字，而一个词则表示一个或多个汉字。在我们的实践当中，每一个字都对应着`BIO`中的一个实体标签。输入模型的是，就是每个字对应的embedding结果，同样，我们还是选择使用预训练的字向量作为每个字的编码。

+ 为什么要选择预训练的字向量，而不是随机初始化
  + 预训练的字向量已经包含了句子中字与字之间的语义信息，在此基础上进行训练，会使得模型收敛得更快，训练结果较好

#### BiLSTM的输出

![截屏2021-05-21 上午11.31.24](/Users/lixuanhong/Library/Application Support/typora-user-images/截屏2021-05-21 上午11.31.24.png)

由上图可见，BiLSTM的输出是每个词对应的实体类型的打分结果。比如对于第一个词，分数最高的是`I-Person` 。一个句子中所有单词的打分结果都会作为CRF的输入。类别序列中分数最高的类别就是我们预测的最终结果。

#### 如果没有CRF层会是什么样？

没有CRF也是可以的，直接将BiLSTM打分的结果作为最终结果。但是这样未必准确。

==自评==：所以CRF的作用在于能够辅助BiLSTM进行预测，保证预测结果是有效的。

#### 为什么CRF能够保证预测结果是有效的？

+ CRF层可以学习到句子的约束条件，可能的约束条件为：
  + 句子的开头应该是`B-`或`O`，而不是`I-`。
  + `B-label1 I-label2 I-label3…`，在该模式中，类别1, 2, 3应该是同一种实体类别。比如，`B-Person I-Person` 是正确的，而`B-Person I-Organization`则是错误的。
  + `O I-label`是错误的，命名实体的开头应该是`B-`而不是`I-` 。

#### CRF层

+ 损失函数（<font color=red>关键</font>）

  + Emission score （发射分数，状态分数）

    + 状态分数来自BiLSTM层的输出
    + $X_{i, y_i}$ 代表状态分数，$i$ 是单词的位置索引（假设共有5个单词），$y_i$ 是类别的索引（假设共有5个类别），可以表示为：$x_{i=1,y_2= 2} = x_{\omega_1, B_{organization}} = 0.1$，表示单词 $\omega_1$ 被预测为 `B-Organization` 的分数为0.1 

  + Transition score （转移分数）

    + CRF需要一个转移分数矩阵（<font color=red>这里应该和状态转移矩阵是一个意思</font>，矩阵除了每个实体类型外，还包括了句子头`start`和句子尾`end`），句子中每个单词的实体类型都会有一个转移分数，也就是这个单词的实体类型A转移为实体类型B的分数（可以理解为概率，实体类型A下一个是实体类型B的概率）
      + 这个分数表示为：$t_{A->B}$
    + 这个矩阵能够学习到一些句子的约束条件。比如上述三个约束条件，不合理的实体类型转移的分数就会非常低，在CRF的计算中就会抛弃这些分数很低的转移情况。
    + 如何得到这个转移矩阵：
      + 转移矩阵是BiLSTM-CRF模型的一个参数。在训练模型之前，可以**随机初始化转移矩阵**的分数。这些分数将随着训练的迭代过程被更新，换句话说，CRF层可以自己学到这些约束条件。
      + ==自评==：在自己的模型，就是选择了随机初始化的方式来制定状态转移矩阵

  + 损失函数计算：

    + 真实路径分数：<font color=red>是所有路径中分数最高的</font>

    + 一个包含2个单词的句子，可能的类别序列假设有`n`种，每种可能路径的分数为$P_i$（其中，$P_i$的计算为$e^{s_1}$，这里的 $e$ 为常数，要求的是$s_i$），那么路径的总分为每条路径的分数和

    + 损失函数：$loss = \frac {P_{RealPath}}{P_1 + P_2 + ... + P_n}$

      + 怎么定义路径的分数，也就是计算 $s_i$？
        + 以 `START B-Person I-Person O B-Organization O END`这条真实路径来说：
        + 句中共有5个单词，从 $w_1$ 到 $w_5$，加上`start`和`end`，记为 $w_0$ 和 $w_6$。
        + $s_i = Emission Score + Transition Score$，其中
        + $Emission Score = x_{0,start} + x_{1,B-person} + x_{2,I-person} + x_{3, O} + x_{4, B-organization} + x_{5, O} + x_{6, end}$
          + 这些分数来自`BiLSTM`层，`start`和`end`的分数可以置为0
        + $Transition Score = t_{start->B-person} + t_{B-person->I-person} + t_{I-person->O} + t_{O->B-organization} + t_{B-orgnization->O} + t_{O->end}$
          + 这些分数来自CRF层，也就是一个实体类型转移到下一个实体类型的分值，实体顺序来自真实路径中的实体预测类型

      + 怎么计算所有路径的总分？

        + 将损失函数改变为 $log loss = log \frac {P_{RealPath}}{P_1 + P_2 + ... + P_n}$

        + 由于我们的目的是减小损失函数，这里我们给损失函数加上负号

          $log loss$

          $= - log \frac {P_{RealPath}}{P_1 + P_2 + ... + P_n}$

          $= - log \frac {e^s_{RealPath}} {e^{s_1} + e^{s_2} + ... + e^{s_n}}$

          $= - (log(e^s_{RealPath}) - log(e^{s_1} + e^{s_2} + ... + e^{s_n}))$

          $= - (s_{RealPath}-log(e^{s_1} + e^{s_2} + ... + e^{s_n}))$

          $= - (\sum^n_{i=1}x_{i,y_i}+\sum^{n-1}_{i=1}t_{y_i, y_j}-log(e^{s_1} + e^{s_2} + ... + e^{s_n}))$

        + 括号内的前两项，已经知道是如何计算的了，现在需要计算`log`内的式子

        + 接下来使用两个变量，`obs`（表示<font color=red>观测值</font>）和`previous`

          + 其中`obs`表示当前实体所带的信息，`previous`存储了之前的结果

          + 假设共有3个实体，分别有2种实体类型，那么在一个状态转移的过程中，

          + 对于$w_0$来说，由于没有之前的信息，所以`previous`为空，而$s_1 = x_{01}， s_2 = x_{02}$, 那么$obs = [x_{01}, x_{02}]$，并且$log(e^{x_{01}} + e^{x_{02}})$

          + 对于$w_0$向$w_1$进行状态转移时，$obs = [x_{01}, x_{02}]$，同时$previous = [x_{11}, x_{12}]$

          + 然后我们分别对`obs`和`previous`进行扩展，得到（<font color=red>这里需要注意 previous 和 obs 中元素的排列方式</font>）

            $previous = \left[ \begin{matrix} x_{01} & x_{01}\\ x_{02} & x_{02}  \end{matrix} \right]$

            $obs = \left[ \begin{matrix} x_{11} & x_{12}\\ x_{11} & x_{12}  \end{matrix} \right]$

          + 计算这条路径上的总分数，将`previous`，`obs`和转移矩阵按位进行相加

            $Score = \left[ \begin{matrix} x_{01} & x_{01}\\ x_{02} & x_{02}  \end{matrix} \right ] + \left[ \begin{matrix} x_{11} & x_{12}\\ x_{11} & x_{12}  \end{matrix} \right] + \left[ \begin{matrix} t_{11} & t_{12}\\ t_{21} & t_{22}  \end{matrix} \right] = \left[ \begin{matrix} x_{01}+x_{11}+t_{11} & x_{01}+x_{12}+t_{12}\\ x_{02}+x_{11}+t_{21} & x_{02}+x_{12}+t_{22}  \end{matrix} \right ]$

          + 下一次迭代时，`previous`的值就等于

            $previous = \left[ \begin{matrix} log(e^{x_{01}+x_{11}+t_{11}} + e^{x_{02}+x_{11}+t_{21}}) & log(e^{x_{01}+x_{12}+t_{12}} + e^{x_{02}+x_{12}+t_{22} }) \end{matrix} \right]$

          + 问题解答：

            1. 为什么`Score`的结果是2\*2的矩阵，但是`previous`是一个1\*2的矩阵？
               + 因为`previous`表示的是一个状态分数，当前的实体类型总共有2个，之前的`previous`的结果维度也是1\*2，那么此时的`previous`的结果维度也应该保持一致
            2. `score` 2\*2矩阵是如何变为`previous` 1\*2矩阵的？
               + 这里采用的方法是，<font color=red>在每一列上进行求和</font>，也就是将 2\*2矩阵 压缩成 1\*2矩阵

          + 那么这迭代过程会变为：

            $TotalScore = (\omega_0 -> \omega_1)$

            $=log(e^{previous[0]}, e^{previous[1]})$

            $=log(e^{log(e^{x_{01}+x_{11}+t_{11}} + e^{x_{02}+x_{11}+t_{21}})}+e^{log(e^{x_{01}+x_{12}+t_{12}} + e^{x_{02}+x_{12}+t_{22} })})$

            $=log(e^{x_{01}+x_{11}+t_{11}} + e^{x_{02}+x_{11}+t_{21}}+e^{x_{01}+x_{12}+t_{12}} + e^{x_{02}+x_{12}+t_{22} })$

          + <font color=red>通过这个结果，我们可以看出来，这就是我们想要的</font> $log(e^{s_1} + e^{s_2} + ... + e^{s_n})$

          + 这里总共有4个结果，依次将他们进行命名，分别为$s_1, s_2, s_3, s_4$

            $s_1 = x_{01}+x_{11}+t_{11},  label1 - label1$

            $s_2 = x_{02}+x_{11}+t_{21}, label2 -label1$

            $s_3 = x_{01}+x_{12}+t_{12}, label1-label2$

            $s_4 = x_{02}+x_{22}+t_{22}, label2-label2$

            <font color=red> 这就是状态转移的过程，分别表示了两个状态之间的转移分值，有几个这样的分值就代表有几个转移路径。对于2个待预测的实体，并且实体类型有2个，其路径数量为 </font>： $PathNum = EntityTypeNum^{waitedEntityNum}$

          + 当一个句子中有3个实体，即3个字，实体类型有2个，那么其路径总数为2的3次方，为8个。

      + 计算所有路径总分时，是否需要列举出所有可能的路径？
        + 答案是不用，这里所说的不用，主要是由于CRF中的状态矩阵和转移矩阵中的元素之间计算就已经能够表达每条路径上总分

  + 如何对每个实体字进行实体类型预测？

    + 假设一个句子中有3个实体，一共有2个实体类型供模型进行预测

    + 需要写明状态矩阵和转移矩阵

    + 同样，`Previous`存储了上一个步骤的最终结果，`obs`代表当前单词包含的信息（发射分数）

    + `alpha0` 是历史最佳的分数 ，`alpha1` 是最佳分数所对应的类别索引。

    + 观测第1个实体字，$\omega_0$

      + if $obs = [x_{01}=0.2, x_{02}=0.8]$, 那么最佳预测结果是l2。

    + 观测第2个实体字，$\omega_1$

      + $obs = [x_{01}, x_{02}]$，$previous = [x_{11}, x_{12}]$ （和上面的结果一样）

      + 对 obs 和 previous 进行扩展，然后和转移矩阵进行矩阵间的按位相加，得到上述的一样的score结果

      + 从这里开始与上述计算路径分数不同，下一次迭代前修改`previous`的结果

        $previous= [max(score[0][0],score[1][0]), max(score[1][0], score[1][1])]$

        <font color=red> 从式子上看，score矩阵中的每列作为一组进行求最大 </font>

      + 假设打分的结果为：$score=\left[ \begin{matrix} 0.2 & 0.3\\ 0.5 & 0.4  \end{matrix} \right]$， 那么 $previous = [0.5, 0.4]$

      + 这个意思是：<font color=red>previous存储的是当前单词对应各类别的最佳路径得分。W1被预测为L1类别的最高分是0.5（因为0.5排在第一个位置），路径是L2->L1（L2是预测第一个实体的结果），W1被预测为L2类别的最高分是0.4（因为0.4排在第二个位置），路径是L2->L2。</font>

      + $alpha0 = [(0.5, 0.4)]$，存储这轮的最佳分数
      + $alpha1 = [(1,1)]$，存储最佳分数对应的索引，<font color=red>也就是看最佳分数的所在score中的行索引</font>。0.5和0.4都在第1行

    + 观测第3个实体，$\omega_3$

      + 假设打分的结果为：$score=\left[ \begin{matrix} 0.6 & 0.9\\ 0.8 & 0.7  \end{matrix} \right]$， 那么 $previous = [0.8, 0.9]$
      + 由于$\omega_3$是最后一个实体字了，那么0.9对应着的路径，就是我们预测的结果
      + $alpha0 = [(0.5, 0.4), (0.8, 0.9)]$
      + $alpha1 = [(1,1), (1,0)]$

    + 根据 `alpha0` 和 `alpha1`将被用来找到最佳路径

      + 先看alpha0，alpha0中最后一个单词对应的类别得分分别是0.8 和 0.9，那么0.9对应的类别L2就是最佳预测结果
      + 再看alpha1，L2对应的索引是0, 0表示之前一个单词对应的类别是L1，所以W1-W2的最佳路径是： L1->L2
      + alpha1=（1,1），我们已经知道W1的预测结果是L1，对应的索引是0，（1,1）[0] = 1，所以W0对应的类别是L2
      + 我们预测的最佳路径是 L2-> L1 -> L2 。