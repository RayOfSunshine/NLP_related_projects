https://fyubang.com/2019/12/30/entity-linking/

### 实体链接

+ 目的：把文本中的mention链接到KG里的entity的任务

  + Mention：自然文本中表达实体的语言片段
  + 也就是将一句话中能够表达实体的词语全部加到图谱里面

+ EL的应用

  + **Question Answering**：EL是KBQA的刚需，linking到实体之后才能查询图数据库；
  + **Content Analysis**：舆情分析、内容推荐、阅读增强；
  + **Information Retrieval**：基于语义实体的搜索引擎，google搜索一些实体，右侧会出现wikipedia页面；
  + **Knowledge Base population**：扩充知识库，更新实体和关系。

+ 工作分类

  + **End-to-End**：先从文本中提取到实体mention (即NER)，对应到候选实体，然后将提取到的entities消除歧义，映射到给定的KB中。
  + **Linking-Only**：与第一种方法对比，跳过了第一步。该方法直接将text和mention作为输入，找到候选实体并消除歧义，映射到给定的KB中。

+ Linking-Only：

  + **Mention Variations**：同一实体有不同的mention

    + <font color=red>一个实体有多个指代或者别名（实体对齐）</font>
    + 解决方法：**Candidate Entity Generation**：从mention出发，找到KB中所有可能的实体，组成候选实体集 (candidate entities)
      + 最重要的方法：Name Dictionary ( `{mention: entity}` )，也就是<font color=red>配别名</font>
      + 首字母缩写、模糊匹配、昵称、拼写错误等。
      + 如做百科问答或是通用文本的阅读增强，就很依赖于**wikipedia和搜索引擎**；
      + 如果是某个具体的行业领域，就需要通过一些**启发式的方法、用户日志、网页爬取，甚至人工标注的方法**来构建Name Dictionary。

  + **Entity Ambiguity**: 同一mention有不同的实体：

    + <font color=red> 一个名字，在不同文本中表达的含义不一样（实体消岐）</font>

    + 解决方法：**Entity Disambiguation**：从candidate entities中，选择最可能的实体作为预测实体。

      + 实体消歧的特征分为，==context独立和context不独立的==。

      + 独立的有：<font color=red>mention到实体的LinkCount、实体自身的一些属性</font>（比如热度、类型等等）。其中，**LinkCount作为一个先验知识，在消歧时，往往很有用**，比如当我们在问“姚明有多高？”时，大概率都是在问<篮球运动员姚明>，而不是其他不为人知的“姚明”。虽然context中完全没有包含篮球运动员这一信息，但大多数情况下，根据“姚明”到<篮球运动员姚明>的LinkCount最高，选其作为实体进行查询，都会是一个不错的答案。
      + 不独立的有：<font color=red>文本的context、实体间的coherence (一致性)</font>。这部分，可深入挖掘的东西比较多，文本context可以用一些深度学习的方法去深度理解文本的语义，从而实现消歧；实体间的一致性更加有趣，由于文本包含的所有的mention都没有确定，所以**全局地进行entities的消歧实际上是一个NP-hard的问题**。因此，如何更加快速有效地利用一致性特征，是一个非常有趣的方向。
      + 消岐方法：
        + **Learning to Rank Methods**：Point-wise、Pair-wise、List-wise。由于ED任务ground truth只有一个实体，一般都是用point-wise来做。输入是文本的context、mention、某个entity的一些attributes，输出mention指向该entity的置信度，以此rank，选出最可信的entity；
        + **Probabilistic Methods**：Incorporate heterogeneous knowledge into a probabilistic model。结合不同信息，得到条件概率 ![[公式]](https://www.zhihu.com/equation?tex=P%28e%7Cm%2C+c%29) ，其中 c 是输入文本，e 为实体， m 是mention。比如用归一化的LinkCount信息，作为先验概率 ![[公式]](https://www.zhihu.com/equation?tex=P%28e%7Cm%29) ；
        + **Graph-Based Approaches**：maximize coherene between entities。利用图特征 (entity embedding、relation)，在消歧时，考虑全局消歧后实体的一致性；



+ 实践一：https://github.com/AlexYangLi/ccks2019_el

  ![el](https://tva1.sinaimg.cn/large/008i3skNgy1gtf4rjpp3qj61jv0lmdmi02.jpg)

  + 方法：语义匹配，待消歧文本（mention embedding）以及知识库中候选实体所有三元组拼接起来的实体描述文本（entity embedding）作为匹配文本对，使用神经网络对它们进行建模得到各自的 representation，然后使用 cosine 相似度进行匹配度打分，选择得分最高的候选实体输出。
  + 使用模型：BiLSTM + CNN
  + mention embedding
    + 需要加入mention的位置信息，拼接每个字与mention的相对位置向量，反映他们与mention在距离上的紧密程度
    + 经过 BiLSTM+CNN 后，我们只选取 mention 部分的输出序列来产生 mention embedding。具体而言，我们将 mention 输出序列中第一个字向量、最后一个字向量、 maxpooling 向量以及使用 self-attention 得到的向量进行拼接，最后通过一层简单的全连接层得到 mention 表达。
  + entity embedding
    + 对隐藏向量序列进行maxpooling，选择时间步上值最大的进行输出。
    + 考虑 entity 描述文本每个字与 mention 的相似度，使用 mention embedding 与隐藏向量序列进行 attention 计算，而后使用隐藏向量的加权和结果作为 entity 表达。我们主要尝试了 3 种 attention 权重的计算方式
  + 训练细节
    + 训练实体消歧模型时，我们采用的的损失函数是 $L(m, e+, e-) = max(m+score(m, e-)-score(m, e+)$, 0)，即正确实体与 mention 的匹配得分要比错误实体的匹配得分至少高出一个 margin 的大小。
